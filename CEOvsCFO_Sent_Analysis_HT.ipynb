{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c812094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971a92b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our lemmatizer and list of stopwords\n",
    "wn = WordNetLemmatizer()\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb0def7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bob_Swan_CEO = \"\"\"Thanks, Pat and welcome back to Intel. It has been an honor to lead this incredible company and its talented team. It gives me great confidence in Intel's future knowing that I'll be passing the baton to Pat whose technical expertise, industry knowledge, execution track record, and commitment to our company are indisputable. Over the last two years, we made significant progress on our strategy to transform Intel into a multi-architecture XPU company, to move from silicon to solutions, and to contemporize our IDM model.\n",
    "I am proud of what we're able to achieve together as an Intel team in a relatively short period of time and echo Omar's words that Intel is in a strong strategic and financial position as we make this transition. As demonstrated by the results we announced today, demand for Intel's innovative technologies remains very strong and our investments to capitalize on future growth opportunities are paying off. Our Q4 results significantly exceeded our expectations capping off our fifth consecutive year of record revenue. We generated $20 billion in revenue and $1.52 in EPS, exceeding our guidance by $2.6 billion and $0.42 respectively.\n",
    "For the full year, we delivered $77.9 billion in revenue, up 8%, and $5.30 in EPS, up 9%. The client, data center, memory, and Mobileye businesses each set all-time revenue records. In Q4, we continued to advance our three strategic priorities: improving our execution to strengthen our core business, extending our reach to accelerate growth and redefine our position in the industry, and continuing to thoughtfully deploy capital to create value for our shareholders. Let me briefly discuss some of the highlights.\n",
    "Starting with improving our execution to strengthen our core business, let me start with an update on process technology and our product road map. Over the last few years, we've been following the IDM model to ensure we can deliver a predictable cadence of leadership products, preserve our IDM advantage, continue to invest in process technology leadership, and generate attractive returns on capital. This evolution includes a disaggregated design strategy, adoption of standard industry processes and common tools, flows, and methods, and deeper engagement with the industry ecosystem. In July, we highlighted a challenge with our 7-nanometer technology and starting a process to improve it while evaluating the best approach for our 2023 product lineup.\n",
    "Since that time, we have made tremendous progress on our 7-nanometer technology. When 7-nanometer was originally defined, the flow contained a particular sequence of steps that contributed to the defect issue we discussed in July. By rearchitecting these steps, we've been able to resolve the defects. As part of this work over the last six months, we also streamlined and simplified our 7-nanometer process architecture to better ensure we'll be able to deliver on our 2023 product road map.\n",
    "The inline data we have been collecting and our pipeline of proven yield development projects gives us confidence in our ability to deliver on our commitments going forward. At the same time, as Pat mentioned, we will continue to leverage the relationships we've developed over the years with our external foundry partners and believe they can play a larger role in our product road map given our disaggregated designs. Once Pat has had a chance to join, he'll further assess our analysis and drive the final manufacturing decision for our 2023 CPU products. Therefore, we'll communicate that decision soon after he takes over, but not today.\n",
    "Turning to products. We've qualified several new products in the fourth quarter, and we have an incredibly exciting lineup of CPUs for '21 and '22. Just a couple of weeks ago at CES, we introduced more than 50 processors resulting in more than 500 new designs for laptops and desktops coming to market in 2021. We are also seeing tremendous market response for PCs based on our new 11th Gen Intel Core Tiger Lake processors.\n",
    "Our PC customers now have more than 150 Tiger Lake-based systems in the market, well ahead of expectations. We believe we gained market share as PCs, CPU units grew an impressive 33% in the quarter. In a market where competitors are seeing supply challenges, this is a powerful example of the incredible value and scale of our factory network as we continue to deliver greater performance and cost efficiencies for our customers. Moving to the data center, we are now shipping our first 10-nanometer based Xeon Scalable CPU Ice Lake and will be ramping volume through the first quarter.\n",
    "Customers are going to see significant value in Ice Lake across cloud, network, and edge workloads with excellent performance improvement and innovations such as PCIe Express Gen 4, next-generation Intel Optane Persistent Memory, and security enhancements such as SGX. As we look ahead, we are excited about the capabilities we are bringing to customers with Alder Lake for mobile and desktop PCs and Sapphire Rapids for the data center. These products take advantage of our Enhanced SuperFin process technology in numerous architectural improvements and both are broadly sampling to customers. We will qualify Alder Lake desktop and notebook for production and begin our volume ramp in the second half of '21, and we expect production qualification of Sapphire Rapids at the end of 2021.\n",
    "In the expanded market opportunity in front of us, CPUs are critical, but multiple architectures or XPUs will be required to help customers optimize for specific workloads. We had a big XPU leap in the fourth quarter as we entered the discrete graphics market with Intel Iris Xe MAX graphics, Intel's first Xe-based discrete GPU. We are now shipping discrete graphics into thin and light notebooks from Acer, Asus, and Dell, and we introduced our first discrete GPU for the data center, which is already delivering great cloud gaming experiences for customers such as Tencent. We also announced the gold release of one API, our cross-industry open standards-based unified programming model that delivers a common developer experience across architectures.\n",
    "Second, we've made strong progress extending our reach to accelerate our growth. Over the past several years, we have been making investments that have positioned us to lead key technology inflections such as AI, 5G network transformation, and the intelligent autonomous edge. We infuse AI capabilities into everything we make from the cloud to PCs and we see tremendous growth prospects as we build our position in data center training to complement the strength of our Intel Xeon for inference. We made a significant step in AI this quarter when Amazon announced EC2 instances that will leverage up to eight of our Habana Gaudi AI training accelerators, and deliver up to 40% better price-performance than current GPU-based EC2 instances for machine learning workloads.\n",
    "We've also invested to drive networking workload convergence on Intel silicon. In 2020, we expanded our footprint into the Radio Access Network delivering Xeon SoCs, FPGAs, and custom solutions for 5G base station designs and reaching our goal of 40% share, two years ahead of our original target. Today, we are the leading network silicon provider winning in the wireless, enterprise, and cloud networks, and delivering $6 billion in revenue this year, up approximately 20% versus 2019. Finally, we have enviable assets to lead the explosive growth of intelligent and autonomous edge computing.\n",
    "Our IOTG and Mobileye businesses have combined annual revenue of $4 billion. Mobileye delivered a record fourth quarter and had an explosive start to 2021 with a number of exciting CES announcements. Third, we've maintained our discipline in thoughtfully allocating our shareholders' capital. Since 2015, we have grown revenue by more than $22 billion and more than doubled EPS.\n",
    "We've driven spending from 36% of revenue to 25% of revenue while investing in manufacturing capacity expansion, adding more than $1 billion of R&D targeted to higher growth initiatives, and focusing our product portfolio. As a result, we anticipate approximately $12 billion in proceeds from our NAND and McAfee exits over time. At the same time, we've been delivering substantial capital returns to shareholders, including $19.8 billion in 2020 alone through dividends and share buybacks, the latter of which included a $10 billion accelerated share repurchase announced in August. Building on this, today, we announced that we are increasing our annual dividend by $0.07, or 5% from $1.32 to $1.39 per share.\n",
    "Before I pass it to George for more details on our fourth-quarter results, I want to reiterate that I couldn't be more proud of the team at Intel and I cherish the time I've spent here. I look forward to watching Pat and the team's continued progress as they build on Intel's purpose to deliver breakthrough technology that enriches the lives of everyone on the planet. I also thank our investors and analysts on the line today for their continued support of Intel and for our valued engagements over the years.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b905be8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "George_Davis_CFO = \"\"\"Thanks, Bob, and good afternoon everyone. Q4 marked a much stronger than expected finish to a record year. Both Mobileye and our PC-centric segment achieved record quarters. Q4 revenue was $20 billion, exceeding our guidance by $2.6 billion.\n",
    "The revenue beat was broad-based led by stronger than expected notebook and cloud demand, along with contributions from desktop and enterprise and government. Datacenter related demand also led to stronger revenues in NAND. The gross margin for the quarter was 58.4%, exceeding the guide by 3 points due to flow through on higher revenue, and the benefit of Ice Lake server achieving production qualification prior to year-end. Q4 EPS was $1.52, $0.42 above our guide due to strong operational performance, and further boosted by gains from our ICAP portfolio.\n",
    "Excluding a one-time tax adjustment, about two-thirds of our EPS beat was operational and one-third was below the line. For full-year 2020, we achieved record revenue of $77.9 billion, $4.4 billion higher than our January guide, which reflects a one-year acceleration relative to our 2019 Investor Day target. EPS was $5.30, up to $0.43 year over year, and $0.30 higher than our January guide. We generated $21.1 billion of free cash flow, up 25% year on year, and returned 94% of free cash flow to shareholders.\n",
    "In total, we have repurchased approximately $17.6 billion shares as part of our planned $20 billion share repurchases announced in October 2019. We intend to complete the remaining $2.4 billion balance in Q1 '21. Moving briefly to the segment performance, our data center group generated record revenue in 2020, up 11% year over year. In Q4, DCG delivered revenue of $6.1 billion, down 16% year over year driven by enterprise and government weakness, and cloud digestion albeit lower than expected.\n",
    "As a reminder, Q4 '19 was tough to compare with an all-time record for revenue with strength across all segments. DCGs operating margin in Q4 was down $1.4 billion years on year on lower revenue and increased investment. Our other data-centric businesses were up 1% year over year in 2020. In Q4, these businesses were down 5% year over year, driven largely by COVID-related demand impacts, partially offset by Mobileye growth.\n",
    "IOTG revenue was down 16% year over year, due to COVID effects on demand. We expect a recovery in IOTG in 2021 and saw sequential growth of $100 million in the quarter on stabilizing industrial and video segments. Mobileye revenue was up 39% year over year in the quarter and the operating margin was $110 million, both records as IQSoC demand continues to be strong. NSG revenue was $1.2 billion, down 1% year on year on lower ASPs, partially offset by higher volume growth.\n",
    "The operating margin was $76 million. PSG revenue was down 16% year over year, due mostly to 5G ASIC transitions at key accounts in the communications segment. CCG delivered a fifth straight year of record revenue, up 8% year over year. For the quarter, revenue was up 9% year over year, driven by record notebook unit volume.\n",
    "ASPs were down 11%, due to increased volume in consumer entry and education segments. Adjacency revenue was down 31%, driven by modem ramp down and the divestiture of our Home Gateway Business. Operating income was $4.5 billion, up $420 million year over year on higher volume, partially offset by the ramp of 10-nanometer products. Moving to our outlook.\n",
    "As Bob and Trey said, we believe it is important to give Pat time to assume his new role and dig into the business before announcing our full-year 2021 guidance and longer-term plans. However, I will provide our Q1 outlook, and then for the year discuss the high-level headwinds and tailwinds we expect. As a reminder, our outlook for 2021 excludes the NAND business. We expect Q1 revenue of $17.5 billion, down 12% year over year, or down 6% excluding NAND.\n",
    "We see continuing strong demand for notebook PCs in Q1, up significantly year over year and expect desktop volumes to be down year over year. We anticipate further cloud digestion and continued COVID demand impacts on IOTG. The Q1 revenue estimate also includes approximately $500 million in corporate revenue that is one-time in nature and relates to a prepaid revenue arrangement. As we look at the remainder of the year, we see solid TAM growth in our core markets in 2021.\n",
    "We expect PC demand to be more first-half weighted than normal seasonality and expect data-centric demand to be more concentrated in the second half as cloud digestion eases, and COVID impacted markets such as enterprise, data center, and IoT improve. We have strong product road maps but have anticipated a more competitive market and the continued mix shift to entry consumer PCs in our revenue plans this year. Finally, we will see lower modem revenue this year from our exit of that business. Gross margin in Q1 is expected to be approximately 58%, down year over year by approximately 4 points on mix related ASPs from lower Xeon SoC volume, and higher small core PC units partially offset by lower margin impact from divested businesses and some improvements from our DCG adjacencies.\n",
    "Q1 operating margin is expected to be approximately 30%. We are forecasting EPS of approximately $1.10 per share, and a tax rate of 14.5%. With that, let me turn it back over to Trey, and get to your questions.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15f9a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_word(token, stop_words):\n",
    "    # Lemmatize nouns and verbs\n",
    "    clean_token = wn.lemmatize(token, pos='n')\n",
    "    clean_token = wn.lemmatize(clean_token, pos='v')\n",
    "    # remove low value tokens\n",
    "    if ((clean_token not in stop_words) and (len(clean_token) >= 3)): \n",
    "        return clean_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6720091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # lowercase text\n",
    "    text = text.lower()\n",
    "    # remove digits with no letters immediately before or after\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "    # tokenize the document into a list of individual words\n",
    "    tokens = word_tokenize(text)\n",
    "    # clean each individual word\n",
    "    clean_tokens = [clean_word(w, sw) for w in tokens]\n",
    "    # remove any instances of None from the list of clean tokens\n",
    "    clean_tokens = list(filter(None, clean_tokens))\n",
    "    # return the list of clean tokens\n",
    "    return ' '.join(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b761653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(doc):\n",
    "    sw = set(stopwords.words('english'))\n",
    "    regex = re.compile(\"[^a-zA-Z ]\")\n",
    "    re_clean = regex.sub('', doc)\n",
    "    words = word_tokenize(re_clean)\n",
    "    lem = [wn.lemmatize(word) for word in words]\n",
    "    output = [word.lower() for word in lem if word.lower() not in sw]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c77ee056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CEO = pd.DataFrame({\"sentences\": sent_tokenize(Bob_Swan_CEO)})\n",
    "df_CFO = pd.DataFrame({\"sentences\": sent_tokenize(George_Davis_CFO)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2dc5a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CEO[\"preprocessed_sentences\"] = df_CEO.sentences.apply(preprocess_text)\n",
    "df_CFO[\"preprocessed_sentences\"] = df_CFO.sentences.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c14de781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>preprocessed_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thanks, Pat and welcome back to Intel.</td>\n",
       "      <td>thank pat welcome back intel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It has been an honor to lead this incredible c...</td>\n",
       "      <td>honor lead incredible company talented team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It gives me great confidence in Intel's future...</td>\n",
       "      <td>give great confidence intel future know 'll pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Over the last two years, we made significant p...</td>\n",
       "      <td>last two year make significant progress strate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am proud of what we're able to achieve toget...</td>\n",
       "      <td>proud 're able achieve together intel team rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>As demonstrated by the results we announced to...</td>\n",
       "      <td>demonstrate result announce today demand intel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Our Q4 results significantly exceeded our expe...</td>\n",
       "      <td>result significantly exceed expectation cap fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We generated $20 billion in revenue and $1.52 ...</td>\n",
       "      <td>generate billion revenue eps exceed guidance b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>For the full year, we delivered $77.9 billion ...</td>\n",
       "      <td>full year deliver billion revenue eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The client, data center, memory, and Mobileye ...</td>\n",
       "      <td>client data center memory mobileye business se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>In Q4, we continued to advance our three strat...</td>\n",
       "      <td>continue advance three strategic priority impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Let me briefly discuss some of the highlights.</td>\n",
       "      <td>let briefly discus highlight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Starting with improving our execution to stren...</td>\n",
       "      <td>start improve execution strengthen core busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Over the last few years, we've been following ...</td>\n",
       "      <td>last year 've follow idm model ensure deliver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This evolution includes a disaggregated design...</td>\n",
       "      <td>evolution include disaggregated design strateg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>In July, we highlighted a challenge with our 7...</td>\n",
       "      <td>july highlight challenge -nanometer technology...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Since that time, we have made tremendous progr...</td>\n",
       "      <td>since time make tremendous progress -nanometer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>When 7-nanometer was originally defined, the f...</td>\n",
       "      <td>-nanometer originally define flow contain part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>By rearchitecting these steps, we've been able...</td>\n",
       "      <td>rearchitecting step 've able resolve defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>As part of this work over the last six months,...</td>\n",
       "      <td>part work last six month also streamline simpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The inline data we have been collecting and ou...</td>\n",
       "      <td>inline data collect pipeline prove yield devel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>At the same time, as Pat mentioned, we will co...</td>\n",
       "      <td>time pat mention continue leverage relationshi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Once Pat has had a chance to join, he'll furth...</td>\n",
       "      <td>pat chance join 'll ass analysis drive final m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Therefore, we'll communicate that decision soo...</td>\n",
       "      <td>therefore 'll communicate decision soon take t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Turning to products.</td>\n",
       "      <td>turn product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>We've qualified several new products in the fo...</td>\n",
       "      <td>'ve qualify several new product fourth quarter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Just a couple of weeks ago at CES, we introduc...</td>\n",
       "      <td>couple week ago introduce processor result new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>We are also seeing tremendous market response ...</td>\n",
       "      <td>also see tremendous market response base new 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Our PC customers now have more than 150 Tiger ...</td>\n",
       "      <td>customer tiger lake-based system market well a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>We believe we gained market share as PCs, CPU ...</td>\n",
       "      <td>believe gain market share cpu unit grow impres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>In a market where competitors are seeing suppl...</td>\n",
       "      <td>market competitor see supply challenge powerfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Moving to the data center, we are now shipping...</td>\n",
       "      <td>move data center ship first -nanometer base xe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Customers are going to see significant value i...</td>\n",
       "      <td>customer see significant value ice lake across...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>As we look ahead, we are excited about the cap...</td>\n",
       "      <td>look ahead excite capability bring customer al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>These products take advantage of our Enhanced ...</td>\n",
       "      <td>product take advantage enhance superfin proces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>We will qualify Alder Lake desktop and noteboo...</td>\n",
       "      <td>qualify alder lake desktop notebook production...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>In the expanded market opportunity in front of...</td>\n",
       "      <td>expand market opportunity front cpu critical m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>We had a big XPU leap in the fourth quarter as...</td>\n",
       "      <td>big xpu leap fourth quarter enter discrete gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>We are now shipping discrete graphics into thi...</td>\n",
       "      <td>ship discrete graphic thin light notebook acer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>We also announced the gold release of one API,...</td>\n",
       "      <td>also announce gold release one api cross-indus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Second, we've made strong progress extending o...</td>\n",
       "      <td>second 've make strong progress extend reach a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Over the past several years, we have been maki...</td>\n",
       "      <td>past several year make investment position lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>We infuse AI capabilities into everything we m...</td>\n",
       "      <td>infuse capability everything make cloud see tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>We made a significant step in AI this quarter ...</td>\n",
       "      <td>make significant step quarter amazon announce ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>We've also invested to drive networking worklo...</td>\n",
       "      <td>'ve also invest drive network workload converg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>In 2020, we expanded our footprint into the Ra...</td>\n",
       "      <td>expand footprint radio access network deliver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Today, we are the leading network silicon prov...</td>\n",
       "      <td>today lead network silicon provider win wirele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Finally, we have enviable assets to lead the e...</td>\n",
       "      <td>finally enviable asset lead explosive growth i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Our IOTG and Mobileye businesses have combined...</td>\n",
       "      <td>iotg mobileye business combine annual revenue ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Mobileye delivered a record fourth quarter and...</td>\n",
       "      <td>mobileye deliver record fourth quarter explosi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Third, we've maintained our discipline in thou...</td>\n",
       "      <td>third 've maintain discipline thoughtfully all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Since 2015, we have grown revenue by more than...</td>\n",
       "      <td>since grow revenue billion double eps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>We've driven spending from 36% of revenue to 2...</td>\n",
       "      <td>'ve drive spend revenue revenue invest manufac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>As a result, we anticipate approximately $12 b...</td>\n",
       "      <td>result anticipate approximately billion procee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>At the same time, we've been delivering substa...</td>\n",
       "      <td>time 've deliver substantial capital return sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Building on this, today, we announced that we ...</td>\n",
       "      <td>build today announce increase annual dividend ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Before I pass it to George for more details on...</td>\n",
       "      <td>pas george detail fourth-quarter result want r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>I look forward to watching Pat and the team's ...</td>\n",
       "      <td>look forward watch pat team continue progress ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>I also thank our investors and analysts on the...</td>\n",
       "      <td>also thank investor analyst line today continu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentences  \\\n",
       "0              Thanks, Pat and welcome back to Intel.   \n",
       "1   It has been an honor to lead this incredible c...   \n",
       "2   It gives me great confidence in Intel's future...   \n",
       "3   Over the last two years, we made significant p...   \n",
       "4   I am proud of what we're able to achieve toget...   \n",
       "5   As demonstrated by the results we announced to...   \n",
       "6   Our Q4 results significantly exceeded our expe...   \n",
       "7   We generated $20 billion in revenue and $1.52 ...   \n",
       "8   For the full year, we delivered $77.9 billion ...   \n",
       "9   The client, data center, memory, and Mobileye ...   \n",
       "10  In Q4, we continued to advance our three strat...   \n",
       "11     Let me briefly discuss some of the highlights.   \n",
       "12  Starting with improving our execution to stren...   \n",
       "13  Over the last few years, we've been following ...   \n",
       "14  This evolution includes a disaggregated design...   \n",
       "15  In July, we highlighted a challenge with our 7...   \n",
       "16  Since that time, we have made tremendous progr...   \n",
       "17  When 7-nanometer was originally defined, the f...   \n",
       "18  By rearchitecting these steps, we've been able...   \n",
       "19  As part of this work over the last six months,...   \n",
       "20  The inline data we have been collecting and ou...   \n",
       "21  At the same time, as Pat mentioned, we will co...   \n",
       "22  Once Pat has had a chance to join, he'll furth...   \n",
       "23  Therefore, we'll communicate that decision soo...   \n",
       "24                               Turning to products.   \n",
       "25  We've qualified several new products in the fo...   \n",
       "26  Just a couple of weeks ago at CES, we introduc...   \n",
       "27  We are also seeing tremendous market response ...   \n",
       "28  Our PC customers now have more than 150 Tiger ...   \n",
       "29  We believe we gained market share as PCs, CPU ...   \n",
       "30  In a market where competitors are seeing suppl...   \n",
       "31  Moving to the data center, we are now shipping...   \n",
       "32  Customers are going to see significant value i...   \n",
       "33  As we look ahead, we are excited about the cap...   \n",
       "34  These products take advantage of our Enhanced ...   \n",
       "35  We will qualify Alder Lake desktop and noteboo...   \n",
       "36  In the expanded market opportunity in front of...   \n",
       "37  We had a big XPU leap in the fourth quarter as...   \n",
       "38  We are now shipping discrete graphics into thi...   \n",
       "39  We also announced the gold release of one API,...   \n",
       "40  Second, we've made strong progress extending o...   \n",
       "41  Over the past several years, we have been maki...   \n",
       "42  We infuse AI capabilities into everything we m...   \n",
       "43  We made a significant step in AI this quarter ...   \n",
       "44  We've also invested to drive networking worklo...   \n",
       "45  In 2020, we expanded our footprint into the Ra...   \n",
       "46  Today, we are the leading network silicon prov...   \n",
       "47  Finally, we have enviable assets to lead the e...   \n",
       "48  Our IOTG and Mobileye businesses have combined...   \n",
       "49  Mobileye delivered a record fourth quarter and...   \n",
       "50  Third, we've maintained our discipline in thou...   \n",
       "51  Since 2015, we have grown revenue by more than...   \n",
       "52  We've driven spending from 36% of revenue to 2...   \n",
       "53  As a result, we anticipate approximately $12 b...   \n",
       "54  At the same time, we've been delivering substa...   \n",
       "55  Building on this, today, we announced that we ...   \n",
       "56  Before I pass it to George for more details on...   \n",
       "57  I look forward to watching Pat and the team's ...   \n",
       "58  I also thank our investors and analysts on the...   \n",
       "\n",
       "                               preprocessed_sentences  \n",
       "0                        thank pat welcome back intel  \n",
       "1         honor lead incredible company talented team  \n",
       "2   give great confidence intel future know 'll pa...  \n",
       "3   last two year make significant progress strate...  \n",
       "4   proud 're able achieve together intel team rel...  \n",
       "5   demonstrate result announce today demand intel...  \n",
       "6   result significantly exceed expectation cap fi...  \n",
       "7   generate billion revenue eps exceed guidance b...  \n",
       "8               full year deliver billion revenue eps  \n",
       "9   client data center memory mobileye business se...  \n",
       "10  continue advance three strategic priority impr...  \n",
       "11                       let briefly discus highlight  \n",
       "12  start improve execution strengthen core busine...  \n",
       "13  last year 've follow idm model ensure deliver ...  \n",
       "14  evolution include disaggregated design strateg...  \n",
       "15  july highlight challenge -nanometer technology...  \n",
       "16  since time make tremendous progress -nanometer...  \n",
       "17  -nanometer originally define flow contain part...  \n",
       "18        rearchitecting step 've able resolve defect  \n",
       "19  part work last six month also streamline simpl...  \n",
       "20  inline data collect pipeline prove yield devel...  \n",
       "21  time pat mention continue leverage relationshi...  \n",
       "22  pat chance join 'll ass analysis drive final m...  \n",
       "23  therefore 'll communicate decision soon take t...  \n",
       "24                                       turn product  \n",
       "25  've qualify several new product fourth quarter...  \n",
       "26  couple week ago introduce processor result new...  \n",
       "27  also see tremendous market response base new 1...  \n",
       "28  customer tiger lake-based system market well a...  \n",
       "29  believe gain market share cpu unit grow impres...  \n",
       "30  market competitor see supply challenge powerfu...  \n",
       "31  move data center ship first -nanometer base xe...  \n",
       "32  customer see significant value ice lake across...  \n",
       "33  look ahead excite capability bring customer al...  \n",
       "34  product take advantage enhance superfin proces...  \n",
       "35  qualify alder lake desktop notebook production...  \n",
       "36  expand market opportunity front cpu critical m...  \n",
       "37  big xpu leap fourth quarter enter discrete gra...  \n",
       "38  ship discrete graphic thin light notebook acer...  \n",
       "39  also announce gold release one api cross-indus...  \n",
       "40  second 've make strong progress extend reach a...  \n",
       "41  past several year make investment position lea...  \n",
       "42  infuse capability everything make cloud see tr...  \n",
       "43  make significant step quarter amazon announce ...  \n",
       "44  've also invest drive network workload converg...  \n",
       "45  expand footprint radio access network deliver ...  \n",
       "46  today lead network silicon provider win wirele...  \n",
       "47  finally enviable asset lead explosive growth i...  \n",
       "48  iotg mobileye business combine annual revenue ...  \n",
       "49  mobileye deliver record fourth quarter explosi...  \n",
       "50  third 've maintain discipline thoughtfully all...  \n",
       "51              since grow revenue billion double eps  \n",
       "52  've drive spend revenue revenue invest manufac...  \n",
       "53  result anticipate approximately billion procee...  \n",
       "54  time 've deliver substantial capital return sh...  \n",
       "55  build today announce increase annual dividend ...  \n",
       "56  pas george detail fourth-quarter result want r...  \n",
       "57  look forward watch pat team continue progress ...  \n",
       "58  also thank investor analyst line today continu...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3871840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>preprocessed_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thanks, Bob, and good afternoon everyone.</td>\n",
       "      <td>thank bob good afternoon everyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q4 marked a much stronger than expected finish...</td>\n",
       "      <td>mark much stronger expect finish record year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Both Mobileye and our PC-centric segment achie...</td>\n",
       "      <td>mobileye pc-centric segment achieve record qua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4 revenue was $20 billion, exceeding our guid...</td>\n",
       "      <td>revenue billion exceed guidance billion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The revenue beat was broad-based led by strong...</td>\n",
       "      <td>revenue beat broad-based lead stronger expect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Datacenter related demand also led to stronger...</td>\n",
       "      <td>datacenter relate demand also lead stronger re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The gross margin for the quarter was 58.4%, ex...</td>\n",
       "      <td>gross margin quarter exceed guide point due fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q4 EPS was $1.52, $0.42 above our guide due to...</td>\n",
       "      <td>eps guide due strong operational performance b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Excluding a one-time tax adjustment, about two...</td>\n",
       "      <td>exclude one-time tax adjustment two-thirds eps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>For full-year 2020, we achieved record revenue...</td>\n",
       "      <td>full-year achieve record revenue billion billi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EPS was $5.30, up to $0.43 year over year, and...</td>\n",
       "      <td>eps year year higher january guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>We generated $21.1 billion of free cash flow, ...</td>\n",
       "      <td>generate billion free cash flow year year retu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In total, we have repurchased approximately $1...</td>\n",
       "      <td>total repurchase approximately billion share p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>We intend to complete the remaining $2.4 billi...</td>\n",
       "      <td>intend complete remain billion balance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Moving briefly to the segment performance, our...</td>\n",
       "      <td>move briefly segment performance data center g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>In Q4, DCG delivered revenue of $6.1 billion, ...</td>\n",
       "      <td>dcg deliver revenue billion year year drive en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>As a reminder, Q4 '19 was tough to compare wit...</td>\n",
       "      <td>reminder tough compare all-time record revenue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DCGs operating margin in Q4 was down $1.4 bill...</td>\n",
       "      <td>dcgs operate margin billion year year lower re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Our other data-centric businesses were up 1% y...</td>\n",
       "      <td>data-centric business year year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>In Q4, these businesses were down 5% year over...</td>\n",
       "      <td>business year year drive largely covid-related...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>IOTG revenue was down 16% year over year, due ...</td>\n",
       "      <td>iotg revenue year year due covid effect demand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>We expect a recovery in IOTG in 2021 and saw s...</td>\n",
       "      <td>expect recovery iotg saw sequential growth mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mobileye revenue was up 39% year over year in ...</td>\n",
       "      <td>mobileye revenue year year quarter operate mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NSG revenue was $1.2 billion, down 1% year on ...</td>\n",
       "      <td>nsg revenue billion year year lower asp partia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The operating margin was $76 million.</td>\n",
       "      <td>operate margin million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PSG revenue was down 16% year over year, due m...</td>\n",
       "      <td>psg revenue year year due mostly asic transiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CCG delivered a fifth straight year of record ...</td>\n",
       "      <td>ccg deliver fifth straight year record revenue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>For the quarter, revenue was up 9% year over y...</td>\n",
       "      <td>quarter revenue year year drive record noteboo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ASPs were down 11%, due to increased volume in...</td>\n",
       "      <td>asp due increase volume consumer entry educati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Adjacency revenue was down 31%, driven by mode...</td>\n",
       "      <td>adjacency revenue drive modem ramp divestiture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Operating income was $4.5 billion, up $420 mil...</td>\n",
       "      <td>operate income billion million year year highe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Moving to our outlook.</td>\n",
       "      <td>move outlook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>As Bob and Trey said, we believe it is importa...</td>\n",
       "      <td>bob trey say believe important give pat time a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>However, I will provide our Q1 outlook, and th...</td>\n",
       "      <td>however provide outlook year discus high-level...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>As a reminder, our outlook for 2021 excludes t...</td>\n",
       "      <td>reminder outlook exclude nand business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>We expect Q1 revenue of $17.5 billion, down 12...</td>\n",
       "      <td>expect revenue billion year year exclude nand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>We see continuing strong demand for notebook P...</td>\n",
       "      <td>see continue strong demand notebook significan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>We anticipate further cloud digestion and cont...</td>\n",
       "      <td>anticipate cloud digestion continue covid dema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The Q1 revenue estimate also includes approxim...</td>\n",
       "      <td>revenue estimate also include approximately mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>As we look at the remainder of the year, we se...</td>\n",
       "      <td>look remainder year see solid tam growth core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>We expect PC demand to be more first-half weig...</td>\n",
       "      <td>expect demand first-half weight normal seasona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>We have strong product road maps but have anti...</td>\n",
       "      <td>strong product road map anticipate competitive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Finally, we will see lower modem revenue this ...</td>\n",
       "      <td>finally see lower modem revenue year exit busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gross margin in Q1 is expected to be approxima...</td>\n",
       "      <td>gross margin expect approximately year year ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Q1 operating margin is expected to be approxim...</td>\n",
       "      <td>operate margin expect approximately</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>We are forecasting EPS of approximately $1.10 ...</td>\n",
       "      <td>forecast eps approximately per share tax rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>With that, let me turn it back over to Trey, a...</td>\n",
       "      <td>let turn back trey get question</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentences  \\\n",
       "0           Thanks, Bob, and good afternoon everyone.   \n",
       "1   Q4 marked a much stronger than expected finish...   \n",
       "2   Both Mobileye and our PC-centric segment achie...   \n",
       "3   Q4 revenue was $20 billion, exceeding our guid...   \n",
       "4   The revenue beat was broad-based led by strong...   \n",
       "5   Datacenter related demand also led to stronger...   \n",
       "6   The gross margin for the quarter was 58.4%, ex...   \n",
       "7   Q4 EPS was $1.52, $0.42 above our guide due to...   \n",
       "8   Excluding a one-time tax adjustment, about two...   \n",
       "9   For full-year 2020, we achieved record revenue...   \n",
       "10  EPS was $5.30, up to $0.43 year over year, and...   \n",
       "11  We generated $21.1 billion of free cash flow, ...   \n",
       "12  In total, we have repurchased approximately $1...   \n",
       "13  We intend to complete the remaining $2.4 billi...   \n",
       "14  Moving briefly to the segment performance, our...   \n",
       "15  In Q4, DCG delivered revenue of $6.1 billion, ...   \n",
       "16  As a reminder, Q4 '19 was tough to compare wit...   \n",
       "17  DCGs operating margin in Q4 was down $1.4 bill...   \n",
       "18  Our other data-centric businesses were up 1% y...   \n",
       "19  In Q4, these businesses were down 5% year over...   \n",
       "20  IOTG revenue was down 16% year over year, due ...   \n",
       "21  We expect a recovery in IOTG in 2021 and saw s...   \n",
       "22  Mobileye revenue was up 39% year over year in ...   \n",
       "23  NSG revenue was $1.2 billion, down 1% year on ...   \n",
       "24              The operating margin was $76 million.   \n",
       "25  PSG revenue was down 16% year over year, due m...   \n",
       "26  CCG delivered a fifth straight year of record ...   \n",
       "27  For the quarter, revenue was up 9% year over y...   \n",
       "28  ASPs were down 11%, due to increased volume in...   \n",
       "29  Adjacency revenue was down 31%, driven by mode...   \n",
       "30  Operating income was $4.5 billion, up $420 mil...   \n",
       "31                             Moving to our outlook.   \n",
       "32  As Bob and Trey said, we believe it is importa...   \n",
       "33  However, I will provide our Q1 outlook, and th...   \n",
       "34  As a reminder, our outlook for 2021 excludes t...   \n",
       "35  We expect Q1 revenue of $17.5 billion, down 12...   \n",
       "36  We see continuing strong demand for notebook P...   \n",
       "37  We anticipate further cloud digestion and cont...   \n",
       "38  The Q1 revenue estimate also includes approxim...   \n",
       "39  As we look at the remainder of the year, we se...   \n",
       "40  We expect PC demand to be more first-half weig...   \n",
       "41  We have strong product road maps but have anti...   \n",
       "42  Finally, we will see lower modem revenue this ...   \n",
       "43  Gross margin in Q1 is expected to be approxima...   \n",
       "44  Q1 operating margin is expected to be approxim...   \n",
       "45  We are forecasting EPS of approximately $1.10 ...   \n",
       "46  With that, let me turn it back over to Trey, a...   \n",
       "\n",
       "                               preprocessed_sentences  \n",
       "0                   thank bob good afternoon everyone  \n",
       "1        mark much stronger expect finish record year  \n",
       "2   mobileye pc-centric segment achieve record qua...  \n",
       "3             revenue billion exceed guidance billion  \n",
       "4   revenue beat broad-based lead stronger expect ...  \n",
       "5   datacenter relate demand also lead stronger re...  \n",
       "6   gross margin quarter exceed guide point due fl...  \n",
       "7   eps guide due strong operational performance b...  \n",
       "8   exclude one-time tax adjustment two-thirds eps...  \n",
       "9   full-year achieve record revenue billion billi...  \n",
       "10                 eps year year higher january guide  \n",
       "11  generate billion free cash flow year year retu...  \n",
       "12  total repurchase approximately billion share p...  \n",
       "13             intend complete remain billion balance  \n",
       "14  move briefly segment performance data center g...  \n",
       "15  dcg deliver revenue billion year year drive en...  \n",
       "16  reminder tough compare all-time record revenue...  \n",
       "17  dcgs operate margin billion year year lower re...  \n",
       "18                    data-centric business year year  \n",
       "19  business year year drive largely covid-related...  \n",
       "20     iotg revenue year year due covid effect demand  \n",
       "21  expect recovery iotg saw sequential growth mil...  \n",
       "22  mobileye revenue year year quarter operate mar...  \n",
       "23  nsg revenue billion year year lower asp partia...  \n",
       "24                             operate margin million  \n",
       "25  psg revenue year year due mostly asic transiti...  \n",
       "26  ccg deliver fifth straight year record revenue...  \n",
       "27  quarter revenue year year drive record noteboo...  \n",
       "28  asp due increase volume consumer entry educati...  \n",
       "29  adjacency revenue drive modem ramp divestiture...  \n",
       "30  operate income billion million year year highe...  \n",
       "31                                       move outlook  \n",
       "32  bob trey say believe important give pat time a...  \n",
       "33  however provide outlook year discus high-level...  \n",
       "34             reminder outlook exclude nand business  \n",
       "35      expect revenue billion year year exclude nand  \n",
       "36  see continue strong demand notebook significan...  \n",
       "37  anticipate cloud digestion continue covid dema...  \n",
       "38  revenue estimate also include approximately mi...  \n",
       "39  look remainder year see solid tam growth core ...  \n",
       "40  expect demand first-half weight normal seasona...  \n",
       "41  strong product road map anticipate competitive...  \n",
       "42  finally see lower modem revenue year exit busi...  \n",
       "43  gross margin expect approximately year year ap...  \n",
       "44                operate margin expect approximately  \n",
       "45      forecast eps approximately per share tax rate  \n",
       "46                    let turn back trey get question  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_CFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd495013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocesed_sentences</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank pat welcome back intel</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>honor lead incredible company talented team</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>give great confidence intel future know 'll pa...</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>last two year make significant progress strate...</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proud 're able achieve together intel team rel...</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               preprocesed_sentences  compound  positive  \\\n",
       "0                       thank pat welcome back intel    0.6705     0.647   \n",
       "1        honor lead incredible company talented team    0.7579     0.619   \n",
       "2  give great confidence intel future know 'll pa...    0.8750     0.357   \n",
       "3  last two year make significant progress strate...    0.7096     0.315   \n",
       "4  proud 're able achieve together intel team rel...    0.7506     0.252   \n",
       "\n",
       "   negative  neutral  sentiment  \n",
       "0       0.0    0.353          0  \n",
       "1       0.0    0.381          0  \n",
       "2       0.0    0.643          0  \n",
       "3       0.0    0.685          0  \n",
       "4       0.0    0.748          0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ceo_polarity_scores = []\n",
    "\n",
    "for sentence in df_CEO['preprocessed_sentences']:\n",
    "    try:\n",
    "        sentiment = analyzer.polarity_scores(sentence)\n",
    "        compound = sentiment['compound']\n",
    "        pos = sentiment['pos']\n",
    "        neu = sentiment['neu']\n",
    "        neg = sentiment['neg']\n",
    "        ceo_polarity_scores.append({\n",
    "            'preprocesed_sentences': sentence,\n",
    "            'compound': compound,\n",
    "            'positive': pos,\n",
    "            'negative': neg,\n",
    "            'neutral': neu\n",
    "        })\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "ceo_sentiments_df = pd.DataFrame(ceo_polarity_scores)\n",
    "ceo_sentiments_df['sentiment']=0\n",
    "ceo_sentiments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b700bbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocesed_sentences</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank bob good afternoon everyone</td>\n",
       "      <td>0.6597</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mark much stronger expect finish record year</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mobileye pc-centric segment achieve record qua...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>revenue billion exceed guidance billion</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>revenue beat broad-based lead stronger expect ...</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               preprocesed_sentences  compound  positive  \\\n",
       "0                  thank bob good afternoon everyone    0.6597     0.643   \n",
       "1       mark much stronger expect finish record year    0.3818     0.302   \n",
       "2  mobileye pc-centric segment achieve record qua...    0.0000     0.000   \n",
       "3            revenue billion exceed guidance billion    0.0000     0.000   \n",
       "4  revenue beat broad-based lead stronger expect ...    0.2732     0.161   \n",
       "\n",
       "   negative  neutral  sentiment  \n",
       "0     0.000    0.357          0  \n",
       "1     0.000    0.698          0  \n",
       "2     0.000    1.000          0  \n",
       "3     0.000    1.000          0  \n",
       "4     0.093    0.745          0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfo_polarity_scores = []\n",
    "\n",
    "for sentence in df_CFO['preprocessed_sentences']:\n",
    "    try:\n",
    "        sentiment = analyzer.polarity_scores(sentence)\n",
    "        compound = sentiment['compound']\n",
    "        pos = sentiment['pos']\n",
    "        neu = sentiment['neu']\n",
    "        neg = sentiment['neg']\n",
    "        cfo_polarity_scores.append({\n",
    "            'preprocesed_sentences': sentence,\n",
    "            'compound': compound,\n",
    "            'positive': pos,\n",
    "            'negative': neg,\n",
    "            'neutral': neu\n",
    "        })\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "cfo_sentiments_df = pd.DataFrame(cfo_polarity_scores)\n",
    "cfo_sentiments_df['sentiment']=0\n",
    "cfo_sentiments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dcc4746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocesed_sentences</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank pat welcome back intel</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>honor lead incredible company talented team</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>give great confidence intel future know 'll pa...</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.643</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>last two year make significant progress strate...</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.685</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>proud 're able achieve together intel team rel...</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.748</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>demonstrate result announce today demand intel...</td>\n",
       "      <td>0.8658</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.408</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>result significantly exceed expectation cap fi...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>generate billion revenue eps exceed guidance b...</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.745</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>full year deliver billion revenue eps</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>client data center memory mobileye business se...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>continue advance three strategic priority impr...</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>let briefly discus highlight</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.556</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>start improve execution strengthen core busine...</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.698</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>last year 've follow idm model ensure deliver ...</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.737</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>evolution include disaggregated design strateg...</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.842</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>july highlight challenge -nanometer technology...</td>\n",
       "      <td>0.8689</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>since time make tremendous progress -nanometer...</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.682</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-nanometer originally define flow contain part...</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.833</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rearchitecting step 've able resolve defect</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.444</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>part work last six month also streamline simpl...</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.756</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>inline data collect pipeline prove yield devel...</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.573</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>time pat mention continue leverage relationshi...</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.897</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pat chance join 'll ass analysis drive final m...</td>\n",
       "      <td>-0.0772</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.539</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>therefore 'll communicate decision soon take t...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>turn product</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>'ve qualify several new product fourth quarter...</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.747</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>couple week ago introduce processor result new...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>also see tremendous market response base new 1...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>customer tiger lake-based system market well a...</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.769</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>believe gain market share cpu unit grow impres...</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>market competitor see supply challenge powerfu...</td>\n",
       "      <td>0.8591</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.549</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>move data center ship first -nanometer base xe...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>customer see significant value ice lake across...</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>look ahead excite capability bring customer al...</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.807</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>product take advantage enhance superfin proces...</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.688</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>qualify alder lake desktop notebook production...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>expand market opportunity front cpu critical m...</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>big xpu leap fourth quarter enter discrete gra...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ship discrete graphic thin light notebook acer...</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.843</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>also announce gold release one api cross-indus...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>second 've make strong progress extend reach a...</td>\n",
       "      <td>0.8591</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>past several year make investment position lea...</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.824</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>infuse capability everything make cloud see tr...</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>make significant step quarter amazon announce ...</td>\n",
       "      <td>0.6597</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.766</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>'ve also invest drive network workload converg...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>expand footprint radio access network deliver ...</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>today lead network silicon provider win wirele...</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.798</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>finally enviable asset lead explosive growth i...</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>iotg mobileye business combine annual revenue ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>mobileye deliver record fourth quarter explosi...</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.645</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>third 've maintain discipline thoughtfully all...</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.722</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>since grow revenue billion double eps</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>'ve drive spend revenue revenue invest manufac...</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.867</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>result anticipate approximately billion procee...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>time 've deliver substantial capital return sh...</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.675</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>build today announce increase annual dividend ...</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.571</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>pas george detail fourth-quarter result want r...</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.668</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>look forward watch pat team continue progress ...</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.851</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>also thank investor analyst line today continu...</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.430</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                preprocesed_sentences  compound  positive  \\\n",
       "0                        thank pat welcome back intel    0.6705     0.647   \n",
       "1         honor lead incredible company talented team    0.7579     0.619   \n",
       "2   give great confidence intel future know 'll pa...    0.8750     0.357   \n",
       "3   last two year make significant progress strate...    0.7096     0.315   \n",
       "4   proud 're able achieve together intel team rel...    0.7506     0.252   \n",
       "5   demonstrate result announce today demand intel...    0.8658     0.473   \n",
       "6   result significantly exceed expectation cap fi...    0.0000     0.000   \n",
       "7   generate billion revenue eps exceed guidance b...    0.3400     0.255   \n",
       "8               full year deliver billion revenue eps    0.0000     0.000   \n",
       "9   client data center memory mobileye business se...    0.0000     0.000   \n",
       "10  continue advance three strategic priority impr...    0.9300     0.527   \n",
       "11                       let briefly discus highlight    0.3400     0.444   \n",
       "12  start improve execution strengthen core busine...    0.6369     0.302   \n",
       "13  last year 've follow idm model ensure deliver ...    0.7579     0.263   \n",
       "14  evolution include disaggregated design strateg...    0.4588     0.158   \n",
       "15  july highlight challenge -nanometer technology...    0.8689     0.545   \n",
       "16  since time make tremendous progress -nanometer...    0.4215     0.318   \n",
       "17  -nanometer originally define flow contain part...   -0.3400     0.000   \n",
       "18        rearchitecting step 've able resolve defect    0.0516     0.289   \n",
       "19  part work last six month also streamline simpl...    0.6705     0.244   \n",
       "20  inline data collect pipeline prove yield devel...    0.8020     0.427   \n",
       "21  time pat mention continue leverage relationshi...    0.3400     0.103   \n",
       "22  pat chance join 'll ass analysis drive final m...   -0.0772     0.251   \n",
       "23  therefore 'll communicate decision soon take t...    0.0000     0.000   \n",
       "24                                       turn product    0.0000     0.000   \n",
       "25  've qualify several new product fourth quarter...    0.5256     0.253   \n",
       "26  couple week ago introduce processor result new...    0.0000     0.000   \n",
       "27  also see tremendous market response base new 1...    0.0000     0.000   \n",
       "28  customer tiger lake-based system market well a...    0.2732     0.231   \n",
       "29  believe gain market share cpu unit grow impres...    0.8360     0.597   \n",
       "30  market competitor see supply challenge powerfu...    0.8591     0.451   \n",
       "31  move data center ship first -nanometer base xe...    0.0000     0.000   \n",
       "32  customer see significant value ice lake across...    0.9313     0.443   \n",
       "33  look ahead excite capability bring customer al...    0.4767     0.193   \n",
       "34  product take advantage enhance superfin proces...    0.6124     0.312   \n",
       "35  qualify alder lake desktop notebook production...    0.0000     0.000   \n",
       "36  expand market opportunity front cpu critical m...    0.8271     0.472   \n",
       "37  big xpu leap fourth quarter enter discrete gra...    0.0000     0.000   \n",
       "38  ship discrete graphic thin light notebook acer...    0.6249     0.157   \n",
       "39  also announce gold release one api cross-indus...    0.0000     0.000   \n",
       "40  second 've make strong progress extend reach a...    0.8591     0.742   \n",
       "41  past several year make investment position lea...    0.4588     0.176   \n",
       "42  infuse capability everything make cloud see tr...    0.7906     0.333   \n",
       "43  make significant step quarter amazon announce ...    0.6597     0.234   \n",
       "44  've also invest drive network workload converg...    0.0000     0.000   \n",
       "45  expand footprint radio access network deliver ...    0.8020     0.375   \n",
       "46  today lead network silicon provider win wirele...    0.5859     0.202   \n",
       "47  finally enviable asset lead explosive growth i...    0.7964     0.536   \n",
       "48  iotg mobileye business combine annual revenue ...    0.0000     0.000   \n",
       "49  mobileye deliver record fourth quarter explosi...    0.5267     0.355   \n",
       "50  third 've maintain discipline thoughtfully all...    0.4019     0.278   \n",
       "51              since grow revenue billion double eps    0.0000     0.000   \n",
       "52  've drive spend revenue revenue invest manufac...    0.3818     0.133   \n",
       "53  result anticipate approximately billion procee...    0.0000     0.000   \n",
       "54  time 've deliver substantial capital return sh...    0.4939     0.246   \n",
       "55  build today announce increase annual dividend ...    0.5423     0.429   \n",
       "56  pas george detail fourth-quarter result want r...    0.0890     0.200   \n",
       "57  look forward watch pat team continue progress ...    0.4215     0.149   \n",
       "58  also thank investor analyst line today continu...    0.8625     0.570   \n",
       "\n",
       "    negative  neutral  sentiment  \n",
       "0      0.000    0.353          1  \n",
       "1      0.000    0.381          1  \n",
       "2      0.000    0.643          2  \n",
       "3      0.000    0.685          2  \n",
       "4      0.000    0.748          2  \n",
       "5      0.118    0.408          1  \n",
       "6      0.000    1.000          2  \n",
       "7      0.000    0.745          2  \n",
       "8      0.000    1.000          2  \n",
       "9      0.000    1.000          2  \n",
       "10     0.000    0.473          1  \n",
       "11     0.000    0.556          2  \n",
       "12     0.000    0.698          2  \n",
       "13     0.000    0.737          2  \n",
       "14     0.000    0.842          2  \n",
       "15     0.000    0.455          1  \n",
       "16     0.000    0.682          2  \n",
       "17     0.167    0.833          2  \n",
       "18     0.267    0.444          2  \n",
       "19     0.000    0.756          2  \n",
       "20     0.000    0.573          2  \n",
       "21     0.000    0.897          2  \n",
       "22     0.210    0.539          2  \n",
       "23     0.000    1.000          2  \n",
       "24     0.000    1.000          2  \n",
       "25     0.000    0.747          2  \n",
       "26     0.000    1.000          2  \n",
       "27     0.000    1.000          2  \n",
       "28     0.000    0.769          2  \n",
       "29     0.000    0.403          1  \n",
       "30     0.000    0.549          2  \n",
       "31     0.000    1.000          2  \n",
       "32     0.000    0.557          2  \n",
       "33     0.000    0.807          2  \n",
       "34     0.000    0.688          2  \n",
       "35     0.000    1.000          2  \n",
       "36     0.099    0.429          1  \n",
       "37     0.000    1.000          2  \n",
       "38     0.000    0.843          2  \n",
       "39     0.000    1.000          2  \n",
       "40     0.000    0.258          1  \n",
       "41     0.000    0.824          2  \n",
       "42     0.000    0.667          2  \n",
       "43     0.000    0.766          2  \n",
       "44     0.000    1.000          2  \n",
       "45     0.000    0.625          2  \n",
       "46     0.000    0.798          2  \n",
       "47     0.000    0.464          1  \n",
       "48     0.000    1.000          2  \n",
       "49     0.000    0.645          2  \n",
       "50     0.000    0.722          2  \n",
       "51     0.000    1.000          2  \n",
       "52     0.000    0.867          2  \n",
       "53     0.000    1.000          2  \n",
       "54     0.079    0.675          2  \n",
       "55     0.000    0.571          2  \n",
       "56     0.131    0.668          2  \n",
       "57     0.000    0.851          2  \n",
       "58     0.000    0.430          1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in ceo_sentiments_df.iterrows():\n",
    "    pos = row[\"positive\"]\n",
    "    neg = row['negative']\n",
    "    neu = row[\"neutral\"]\n",
    "    \n",
    "    if (pos > neg) and (pos > neu):\n",
    "#         print(f\"{pos} > {neg} and {pos} > {neu} which is {pos > neg} and {pos > neu}\") \n",
    "#         print(type(pos))\n",
    "        ceo_sentiments_df.at[index, 'sentiment'] = 1\n",
    "    elif (neg > pos) and (neg > neu):\n",
    "        row.sentiment = 0\n",
    "#         print(f\"{neg} > {pos} and {neg} > {neu} which is {neg > pos} and {neg > neu}\") \n",
    "#         print(type(neg))\n",
    "        ceo_sentiments_df.at[index, 'sentiment'] = 0\n",
    "    else:\n",
    "        ceo_sentiments_df.at[index, 'sentiment'] = 2\n",
    "                \n",
    "ceo_sentiments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a1a3ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocesed_sentences</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank bob good afternoon everyone</td>\n",
       "      <td>0.6597</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.357</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mark much stronger expect finish record year</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.698</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mobileye pc-centric segment achieve record qua...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>revenue billion exceed guidance billion</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>revenue beat broad-based lead stronger expect ...</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.745</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>datacenter relate demand also lead stronger re...</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.594</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gross margin quarter exceed guide point due fl...</td>\n",
       "      <td>-0.0258</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.736</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eps guide due strong operational performance b...</td>\n",
       "      <td>0.8555</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>exclude one-time tax adjustment two-thirds eps...</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.826</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>full-year achieve record revenue billion billi...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>eps year year higher january guide</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>generate billion free cash flow year year retu...</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.602</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>total repurchase approximately billion share p...</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.694</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>intend complete remain billion balance</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>move briefly segment performance data center g...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dcg deliver revenue billion year year drive en...</td>\n",
       "      <td>-0.6124</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.722</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reminder tough compare all-time record revenue...</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.598</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dcgs operate margin billion year year lower re...</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.640</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>data-centric business year year</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>business year year drive largely covid-related...</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.709</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>iotg revenue year year due covid effect demand</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.824</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>expect recovery iotg saw sequential growth mil...</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.809</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mobileye revenue year year quarter operate mar...</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.696</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nsg revenue billion year year lower asp partia...</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.676</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>operate margin million</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>psg revenue year year due mostly asic transiti...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ccg deliver fifth straight year record revenue...</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.808</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>quarter revenue year year drive record noteboo...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>asp due increase volume consumer entry educati...</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.753</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>adjacency revenue drive modem ramp divestiture...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>operate income billion million year year highe...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>move outlook</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>bob trey say believe important give pat time a...</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.904</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>however provide outlook year discus high-level...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>reminder outlook exclude nand business</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.678</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>expect revenue billion year year exclude nand</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.759</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>see continue strong demand notebook significan...</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.696</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>anticipate cloud digestion continue covid dema...</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.824</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>revenue estimate also include approximately mi...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>look remainder year see solid tam growth core ...</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>expect demand first-half weight normal seasona...</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.772</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>strong product road map anticipate competitive...</td>\n",
       "      <td>0.6124</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.722</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>finally see lower modem revenue year exit busi...</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.761</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>gross margin expect approximately year year ap...</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.704</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>operate margin expect approximately</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>forecast eps approximately per share tax rate</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.732</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>let turn back trey get question</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                preprocesed_sentences  compound  positive  \\\n",
       "0                   thank bob good afternoon everyone    0.6597     0.643   \n",
       "1        mark much stronger expect finish record year    0.3818     0.302   \n",
       "2   mobileye pc-centric segment achieve record qua...    0.0000     0.000   \n",
       "3             revenue billion exceed guidance billion    0.0000     0.000   \n",
       "4   revenue beat broad-based lead stronger expect ...    0.2732     0.161   \n",
       "5   datacenter relate demand also lead stronger re...    0.2732     0.257   \n",
       "6   gross margin quarter exceed guide point due fl...   -0.0258     0.130   \n",
       "7   eps guide due strong operational performance b...    0.8555     0.573   \n",
       "8   exclude one-time tax adjustment two-thirds eps...   -0.2263     0.000   \n",
       "9   full-year achieve record revenue billion billi...    0.0000     0.000   \n",
       "10                 eps year year higher january guide    0.0000     0.000   \n",
       "11  generate billion free cash flow year year retu...    0.7650     0.398   \n",
       "12  total repurchase approximately billion share p...    0.5267     0.306   \n",
       "13             intend complete remain billion balance    0.0000     0.000   \n",
       "14  move briefly segment performance data center g...    0.0000     0.000   \n",
       "15  dcg deliver revenue billion year year drive en...   -0.6124     0.000   \n",
       "16  reminder tough compare all-time record revenue...    0.4019     0.274   \n",
       "17  dcgs operate margin billion year year lower re...    0.0258     0.184   \n",
       "18                    data-centric business year year    0.0000     0.000   \n",
       "19  business year year drive largely covid-related...    0.2732     0.184   \n",
       "20     iotg revenue year year due covid effect demand   -0.1280     0.000   \n",
       "21  expect recovery iotg saw sequential growth mil...    0.3818     0.191   \n",
       "22  mobileye revenue year year quarter operate mar...    0.4215     0.209   \n",
       "23  nsg revenue billion year year lower asp partia...    0.1027     0.176   \n",
       "24                             operate margin million    0.0000     0.000   \n",
       "25  psg revenue year year due mostly asic transiti...    0.0000     0.000   \n",
       "26  ccg deliver fifth straight year record revenue...    0.2263     0.192   \n",
       "27  quarter revenue year year drive record noteboo...    0.0000     0.000   \n",
       "28  asp due increase volume consumer entry educati...    0.3182     0.247   \n",
       "29  adjacency revenue drive modem ramp divestiture...    0.0000     0.000   \n",
       "30  operate income billion million year year highe...    0.0000     0.000   \n",
       "31                                       move outlook    0.0000     0.000   \n",
       "32  bob trey say believe important give pat time a...    0.2023     0.096   \n",
       "33  however provide outlook year discus high-level...    0.0000     0.000   \n",
       "34             reminder outlook exclude nand business   -0.2263     0.000   \n",
       "35      expect revenue billion year year exclude nand   -0.2263     0.000   \n",
       "36  see continue strong demand notebook significan...    0.4215     0.209   \n",
       "37  anticipate cloud digestion continue covid dema...   -0.1280     0.000   \n",
       "38  revenue estimate also include approximately mi...    0.0000     0.000   \n",
       "39  look remainder year see solid tam growth core ...    0.4939     0.375   \n",
       "40  expect demand first-half weight normal seasona...    0.2263     0.112   \n",
       "41  strong product road map anticipate competitive...    0.6124     0.278   \n",
       "42  finally see lower modem revenue year exit busi...   -0.2960     0.000   \n",
       "43  gross margin expect approximately year year ap...   -0.5423     0.085   \n",
       "44                operate margin expect approximately    0.0000     0.000   \n",
       "45      forecast eps approximately per share tax rate    0.2960     0.268   \n",
       "46                    let turn back trey get question    0.0000     0.000   \n",
       "\n",
       "    negative  neutral  sentiment  \n",
       "0      0.000    0.357          1  \n",
       "1      0.000    0.698          2  \n",
       "2      0.000    1.000          2  \n",
       "3      0.000    1.000          2  \n",
       "4      0.093    0.745          2  \n",
       "5      0.149    0.594          2  \n",
       "6      0.134    0.736          2  \n",
       "7      0.000    0.427          1  \n",
       "8      0.174    0.826          2  \n",
       "9      0.000    1.000          2  \n",
       "10     0.000    1.000          2  \n",
       "11     0.000    0.602          2  \n",
       "12     0.000    0.694          2  \n",
       "13     0.000    1.000          2  \n",
       "14     0.000    1.000          2  \n",
       "15     0.278    0.722          2  \n",
       "16     0.128    0.598          2  \n",
       "17     0.176    0.640          2  \n",
       "18     0.000    1.000          2  \n",
       "19     0.106    0.709          2  \n",
       "20     0.176    0.824          2  \n",
       "21     0.000    0.809          2  \n",
       "22     0.095    0.696          2  \n",
       "23     0.149    0.676          2  \n",
       "24     0.000    1.000          2  \n",
       "25     0.000    1.000          2  \n",
       "26     0.000    0.808          2  \n",
       "27     0.000    1.000          2  \n",
       "28     0.000    0.753          2  \n",
       "29     0.000    1.000          2  \n",
       "30     0.000    1.000          2  \n",
       "31     0.000    1.000          2  \n",
       "32     0.000    0.904          2  \n",
       "33     0.000    1.000          2  \n",
       "34     0.322    0.678          2  \n",
       "35     0.241    0.759          2  \n",
       "36     0.095    0.696          2  \n",
       "37     0.176    0.824          2  \n",
       "38     0.000    1.000          2  \n",
       "39     0.000    0.625          2  \n",
       "40     0.116    0.772          2  \n",
       "41     0.000    0.722          2  \n",
       "42     0.239    0.761          2  \n",
       "43     0.211    0.704          2  \n",
       "44     0.000    1.000          2  \n",
       "45     0.000    0.732          2  \n",
       "46     0.000    1.000          2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in cfo_sentiments_df.iterrows():\n",
    "    pos = row[\"positive\"]\n",
    "    neg = row['negative']\n",
    "    neu = row[\"neutral\"]\n",
    "    if (pos > neg) and (pos > neu):\n",
    "#         print(f\"{pos} > {neg} and {pos} > {neu} which is {pos > neg} and {pos > neu}\") \n",
    "#         print(type(pos))\n",
    "        cfo_sentiments_df.at[index, 'sentiment'] = 1\n",
    "    elif (neg > pos) and (neg > neu):\n",
    "        row.sentiment = 0\n",
    "#         print(f\"{neg} > {pos} and {neg} > {neu} which is {neg > pos} and {neg > neu}\") \n",
    "#         print(type(neg))\n",
    "        cfo_sentiments_df.at[index, 'sentiment'] = 0\n",
    "    else:\n",
    "        cfo_sentiments_df.at[index, 'sentiment'] = 2\n",
    "                \n",
    "cfo_sentiments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42c1d9e",
   "metadata": {},
   "source": [
    "# SCORING SENTIMENT USING VADOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d6c3c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the features set (X) and the target vector (y)\n",
    "X = ceo_sentiments_df[\"preprocesed_sentences\"].values\n",
    "y = ceo_sentiments_df[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14ea3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train, test, and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "778d3f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\krist\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26196a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8ae0c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two lists to store vader sentiment scoring\n",
    "y_vader_pred = []\n",
    "y_vader_prob = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4db02cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score sentiment of test set using Vader\n",
    "for comment in X_test:\n",
    "    y_vader_prob.append(analyzer.polarity_scores(comment)[\"pos\"])\n",
    "    sentiment_score = analyzer.polarity_scores(comment)[\"compound\"]\n",
    "    if sentiment_score >= 0.1:\n",
    "        y_vader_pred.append(1)\n",
    "    else:\n",
    "        y_vader_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f46d1352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6862442 ],\n",
       "       [0.95672334],\n",
       "       [0.        ],\n",
       "       [0.82843895],\n",
       "       [0.55177743]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1: Normalizing data using MinMaxScaler from sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np.array(y_vader_prob).reshape(-1,1))\n",
    "y_vader_prob_norm = scaler.transform(np.array(y_vader_prob).reshape(-1,1))\n",
    "y_vader_prob_norm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a68e0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6862442040185471,\n",
       " 0.9567233384853168,\n",
       " 0.0,\n",
       " 0.8284389489953632,\n",
       " 0.5517774343122102]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2: Using a comprehension list (OPTIONAL - RATHER USE MINMAXScaler)\n",
    "normalized = [(x - min(y_vader_prob)) / (max(y_vader_prob) - min(y_vader_prob))\n",
    "              for x in y_vader_prob]\n",
    "normalized[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5f2e87",
   "metadata": {},
   "source": [
    "# SCORING SENTIMENT USING RNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b827295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Tokenizer and fit it with the X text data\n",
    "tokenizer = Tokenizer(lower=True)\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26a72faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: 'intel', token: 1\n",
      "word: 'deliver', token: 2\n",
      "word: 'billion', token: 3\n",
      "word: 'product', token: 4\n",
      "word: ''ve', token: 5\n"
     ]
    }
   ],
   "source": [
    "# Print the first five elements of the encoded vocabulary\n",
    "for token in list(tokenizer.word_index)[:5]:\n",
    "    print(f\"word: '{token}', token: {tokenizer.word_index[token]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cb8456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the text data to numerical sequences\n",
    "X_seq = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce875e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text comment**\n",
      "{'demonstrate result announce today demand intel innovative technology remain strong investment capitalize future growth opportunity pay'}\n"
     ]
    }
   ],
   "source": [
    "# Contrast a sample numerical sequence with its text version\n",
    "print(\"**Text comment**\")\n",
    "print({X[5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1bb489e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Numerical sequence representation**\n",
      "[189, 22, 23, 24, 190, 1, 191, 8, 192, 58, 97, 193, 88, 16, 98, 194]\n"
     ]
    }
   ],
   "source": [
    "print(\"**Numerical sequence representation**\")\n",
    "print(X_seq[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9511f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pad_sequences method from Keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "411b0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the pad size\n",
    "max_words = 140\n",
    "\n",
    "# Pad the sequences using the pad_sequences() method\n",
    "X_pad = pad_sequences(X_seq, maxlen=max_words, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d56d597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training, validation, and testing sets using the encoded data\n",
    "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X_pad, y)\n",
    "\n",
    "X_train_rnn, X_val_rnn, y_train_rnn, y_val_rnn = train_test_split(X_train_rnn, y_train_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6823d2c4",
   "metadata": {},
   "source": [
    "# Build and Train the RNN LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10be1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras modules for model creation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ff0d510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model set-up\n",
    "vocabulary_size = len(tokenizer.word_counts.keys()) + 1\n",
    "embedding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "416f6939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=280))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eccbcea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "        tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f9f3343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 140, 64)           27904     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 280)               386400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 281       \n",
      "=================================================================\n",
      "Total params: 414,585\n",
      "Trainable params: 414,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc2f0677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 775ms/step - loss: -10.7126 - accuracy: 0.0909 - tp: 33.0000 - tn: 0.0000e+00 - fp: 0.0000e+00 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 0.0000e+00 - val_loss: -9.3635 - val_accuracy: 0.2727 - val_tp: 11.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 710ms/step - loss: -11.7044 - accuracy: 0.0909 - tp: 33.0000 - tn: 0.0000e+00 - fp: 0.0000e+00 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 0.0000e+00 - val_loss: -10.1296 - val_accuracy: 0.2727 - val_tp: 11.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 708ms/step - loss: -12.6620 - accuracy: 0.0909 - tp: 33.0000 - tn: 0.0000e+00 - fp: 0.0000e+00 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 0.0000e+00 - val_loss: -10.8504 - val_accuracy: 0.2727 - val_tp: 11.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 726ms/step - loss: -13.5630 - accuracy: 0.0909 - tp: 33.0000 - tn: 0.0000e+00 - fp: 0.0000e+00 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 0.0000e+00 - val_loss: -11.5147 - val_accuracy: 0.2727 - val_tp: 11.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 692ms/step - loss: -14.3933 - accuracy: 0.0909 - tp: 33.0000 - tn: 0.0000e+00 - fp: 0.0000e+00 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 0.0000e+00 - val_loss: -12.1170 - val_accuracy: 0.2727 - val_tp: 11.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 690ms/step - loss: -15.1463 - accuracy: 0.0909 - tp: 33.0000 - tn: 0.0000e+00 - fp: 0.0000e+00 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 0.0000e+00 - val_loss: -12.6592 - val_accuracy: 0.2727 - val_tp: 11.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 911ms/step - loss: -15.8241 - accuracy: 0.0909 - tp: 33.0000 - tn: 0.0000e+00 - fp: 0.0000e+00 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 0.0000e+00 - val_loss: -13.1465 - val_accuracy: 0.2727 - val_tp: 11.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 869ms/step - loss: -16.4331 - accuracy: 0.0909 - tp: 33.0000 - tn: 0.0000e+00 - fp: 0.0000e+00 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 0.0000e+00 - val_loss: -13.5846 - val_accuracy: 0.2727 - val_tp: 11.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 691ms/step - loss: -16.9807 - accuracy: 0.0909 - tp: 33.0000 - tn: 0.0000e+00 - fp: 0.0000e+00 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 0.0000e+00 - val_loss: -13.9807 - val_accuracy: 0.2727 - val_tp: 11.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 723ms/step - loss: -17.4759 - accuracy: 0.0909 - tp: 33.0000 - tn: 0.0000e+00 - fp: 0.0000e+00 - fn: 0.0000e+00 - precision: 1.0000 - recall: 1.0000 - auc: 0.0000e+00 - val_loss: -14.3429 - val_accuracy: 0.2727 - val_tp: 11.0000 - val_tn: 0.0000e+00 - val_fp: 0.0000e+00 - val_fn: 0.0000e+00 - val_precision: 1.0000 - val_recall: 1.0000 - val_auc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2538dfa9188>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "batch_size = 1000\n",
    "epochs = 10\n",
    "model.fit(\n",
    "    X_train_rnn,\n",
    "    y_train_rnn,\n",
    "    validation_data=(X_val_rnn, y_val_rnn),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f28dd17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krist\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# Predict classes using the testing data\n",
    "y_rnn_pred = model.predict_classes(X_test_rnn, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "85f9effd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted2 = (model.predict(X_test_rnn[:10])>0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5dffa50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09b89a4",
   "metadata": {},
   "source": [
    "# MODELS COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0080f0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vader Accuracy: 0.27\n",
      "RNN LSTM Accuracy 0.27\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Vader Accuracy: %.2f\" % (accuracy_score(y_test, y_vader_pred)))\n",
    "print(\"RNN LSTM Accuracy %.2f\" % (accuracy_score(y_test_rnn, y_rnn_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8bcbe3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the confusion_matrix method from sklearn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be046524",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-73dd1cf9a4cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Confusion matrtix metrics from Vader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtn_vader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp_vader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn_vader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtp_vader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_vader_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Dataframe to display confusion matrix from Vader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m cm_vader_df = pd.DataFrame(\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "# Confusion matrtix metrics from Vader\n",
    "tn_vader, fp_vader, fn_vader, tp_vader = confusion_matrix(y_test, y_vader_pred).ravel()\n",
    "\n",
    "# Dataframe to display confusion matrix from Vader\n",
    "cm_vader_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Positive(1)\": [f\"TP={tp_vader}\", f\"FP={fp_vader}\"],\n",
    "        \"Negative(0)\": [f\"FN={fn_vader}\", f\"TN={tn_vader}\"],\n",
    "    },\n",
    "    index=[\"Positive(1)\", \"Negative(0)\"],\n",
    ")\n",
    "cm_vader_df.index.name = \"Actual\"\n",
    "cm_vader_df.columns.name = \"Predicted\"\n",
    "print(\"Confusion Matrix from Vader\")\n",
    "display(cm_vader_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a11bb77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
