{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEO Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key savefig.frameon in file C:\\Users\\krist\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 421 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file C:\\Users\\krist\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 472 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file C:\\Users\\krist\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle, line 473 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.3.4/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>preprocesed_sentences</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>'ve qualify several new product fourth quarter...</td>\n",
       "      <td>0.5256</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>let briefly discus highlight</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>give great confidence intel future know 'll pa...</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.643</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>proud 're able achieve together intel team rel...</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.748</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>look forward watch pat team continue progress ...</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>generate billion revenue eps exceed guidance b...</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>pas george detail fourth-quarter result want r...</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>start improve execution strengthen core busine...</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>49</td>\n",
       "      <td>mobileye deliver record fourth quarter explosi...</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>last year 've follow idm model ensure deliver ...</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y                              preprocesed_sentences  compound  positive  \\\n",
       "0  25  've qualify several new product fourth quarter...    0.5256     0.253   \n",
       "1  11                       let briefly discus highlight    0.3400     0.444   \n",
       "2   2  give great confidence intel future know 'll pa...    0.8750     0.357   \n",
       "3   4  proud 're able achieve together intel team rel...    0.7506     0.252   \n",
       "4  57  look forward watch pat team continue progress ...    0.4215     0.149   \n",
       "5   7  generate billion revenue eps exceed guidance b...    0.3400     0.255   \n",
       "6  56  pas george detail fourth-quarter result want r...    0.0890     0.200   \n",
       "7  12  start improve execution strengthen core busine...    0.6369     0.302   \n",
       "8  49  mobileye deliver record fourth quarter explosi...    0.5267     0.355   \n",
       "9  13  last year 've follow idm model ensure deliver ...    0.7579     0.263   \n",
       "\n",
       "   negative  neutral  sentiment  \n",
       "0     0.000    0.747          1  \n",
       "1     0.000    0.556          0  \n",
       "2     0.000    0.643          1  \n",
       "3     0.000    0.748          1  \n",
       "4     0.000    0.851          0  \n",
       "5     0.000    0.745          0  \n",
       "6     0.131    0.668          0  \n",
       "7     0.000    0.698          1  \n",
       "8     0.000    0.645          1  \n",
       "9     0.000    0.737          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = Path(\"ceo_sentiment.csv\")\n",
    "ceo_df = pd.read_csv(file_path)\n",
    "ceo_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocesed_sentences</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'ve qualify several new product fourth quarter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>let briefly discus highlight</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>give great confidence intel future know 'll pa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>proud 're able achieve together intel team rel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>look forward watch pat team continue progress ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>generate billion revenue eps exceed guidance b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pas george detail fourth-quarter result want r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>start improve execution strengthen core busine...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mobileye deliver record fourth quarter explosi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>last year 've follow idm model ensure deliver ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>evolution include disaggregated design strateg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>build today announce increase annual dividend ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>since time make tremendous progress -nanometer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-nanometer originally define flow contain part...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rearchitecting step 've able resolve defect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>part work last six month also streamline simpl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>inline data collect pipeline prove yield devel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>time pat mention continue leverage relationshi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pat chance join 'll ass analysis drive final m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>last two year make significant progress strate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ship discrete graphic thin light notebook acer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>customer tiger lake-based system market well a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>time 've deliver substantial capital return sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>market competitor see supply challenge powerfu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>customer see significant value ice lake across...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>product take advantage enhance superfin proces...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>look ahead excite capability bring customer al...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>third 've maintain discipline thoughtfully all...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>'ve drive spend revenue revenue invest manufac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>past several year make investment position lea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>infuse capability everything make cloud see tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>make significant step quarter amazon announce ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>expand footprint radio access network deliver ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>today lead network silicon provider win wirele...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>honor lead incredible company talented team</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>demonstrate result announce today demand intel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>continue advance three strategic priority impr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>july highlight challenge -nanometer technology...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>thank pat welcome back intel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>expand market opportunity front cpu critical m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>second 've make strong progress extend reach a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>finally enviable asset lead explosive growth i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>believe gain market share cpu unit grow impres...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>also thank investor analyst line today continu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                preprocesed_sentences  sentiment\n",
       "0   've qualify several new product fourth quarter...          1\n",
       "1                        let briefly discus highlight          0\n",
       "2   give great confidence intel future know 'll pa...          1\n",
       "3   proud 're able achieve together intel team rel...          1\n",
       "4   look forward watch pat team continue progress ...          0\n",
       "5   generate billion revenue eps exceed guidance b...          0\n",
       "6   pas george detail fourth-quarter result want r...          0\n",
       "7   start improve execution strengthen core busine...          1\n",
       "8   mobileye deliver record fourth quarter explosi...          1\n",
       "9   last year 've follow idm model ensure deliver ...          1\n",
       "10  evolution include disaggregated design strateg...          0\n",
       "11  build today announce increase annual dividend ...          1\n",
       "12  since time make tremendous progress -nanometer...          0\n",
       "13  -nanometer originally define flow contain part...          0\n",
       "14        rearchitecting step 've able resolve defect          0\n",
       "15  part work last six month also streamline simpl...          1\n",
       "16  inline data collect pipeline prove yield devel...          1\n",
       "17  time pat mention continue leverage relationshi...          0\n",
       "18  pat chance join 'll ass analysis drive final m...          0\n",
       "19  last two year make significant progress strate...          1\n",
       "20  ship discrete graphic thin light notebook acer...          1\n",
       "21  customer tiger lake-based system market well a...          0\n",
       "22  time 've deliver substantial capital return sh...          0\n",
       "23  market competitor see supply challenge powerfu...          1\n",
       "24  customer see significant value ice lake across...          1\n",
       "25  product take advantage enhance superfin proces...          1\n",
       "26  look ahead excite capability bring customer al...          0\n",
       "27  third 've maintain discipline thoughtfully all...          0\n",
       "28  've drive spend revenue revenue invest manufac...          0\n",
       "29  past several year make investment position lea...          0\n",
       "30  infuse capability everything make cloud see tr...          1\n",
       "31  make significant step quarter amazon announce ...          1\n",
       "32  expand footprint radio access network deliver ...          1\n",
       "33  today lead network silicon provider win wirele...          1\n",
       "34        honor lead incredible company talented team          1\n",
       "35  demonstrate result announce today demand intel...          1\n",
       "36  continue advance three strategic priority impr...          1\n",
       "37  july highlight challenge -nanometer technology...          1\n",
       "38                       thank pat welcome back intel          1\n",
       "39  expand market opportunity front cpu critical m...          1\n",
       "40  second 've make strong progress extend reach a...          1\n",
       "41  finally enviable asset lead explosive growth i...          1\n",
       "42  believe gain market share cpu unit grow impres...          1\n",
       "43  also thank investor analyst line today continu...          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ceo_df.drop([\"Y\", \"compound\", \"positive\", \"negative\", \"neutral\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the features set `X` and the target vector `y` by assigning the `comment` column to `X` and the `sentiment` column to `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the features set (X) and the target vector (y)\n",
    "X = ceo_df[\"preprocesed_sentences\"].values\n",
    "y = ceo_df[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `train_test_split` method from `sklearn` to create the training, testing, and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train, test, and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Sentiment Using VADER\n",
    "\n",
    "In this section, you will use VADER sentiment from the `nltk` library to score the sentiment of the testing set. Later, you will assess model performance using metrics such as accuracy, precision, recall, among others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries for sentiment scoring using Vader\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by downloading or updating the VADER lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\krist\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download/Update the VADER Lexicon\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of the `SentimentIntensityAnalyzer` and name it `analyzer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define two lists to store the sentiment scoring results as follows:\n",
    "\n",
    "* `y_vader_pred` will save the scored sentiment, `1` for positive or `0` for negative.\n",
    "\n",
    "* `y_vader_prob` will store the normalized value of the `pos` polarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two lists to store vader sentiment scoring\n",
    "y_vader_pred = []\n",
    "y_vader_prob = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `for` loop to iterate across all the comments in the `X` set and score the sentiment of each review comment. Update the two lists for sentiment scores as follows:\n",
    "\n",
    "* Append the `pos` score to the `y_vader_prob`, you will normalize this list's values later.\n",
    "\n",
    "* To score a review comment as positive or negative, we will use the `compound` polarity score; as you may remember from the NLP unit, the `compound` score ranges between `-1` (most extreme negative) and `+1` (most extreme positive). Following the recommendations from [this research paper](https://scholar.smu.edu/cgi/viewcontent.cgi?article=1051&context=datasciencereview), we will define a threshold of `0.1` to label a review as positive, if the `compound` score is greater than or equal to `0.1`, the review comment will be positive (append `1` to `y_vader_pred`); if the `compound` score is below `0.1`, the review comment will be negative (append `0` to `y_vader_pred`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score sentiment of test set using Vader\n",
    "for comment in X_test:\n",
    "    y_vader_prob.append(analyzer.polarity_scores(comment)[\"pos\"])\n",
    "    sentiment_score = analyzer.polarity_scores(comment)[\"compound\"]\n",
    "    if sentiment_score >= 0.1:\n",
    "        y_vader_pred.append(1)\n",
    "    else:\n",
    "        y_vader_pred.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the values from the `pos` polarity score to plot the ROC curve; we will consider the `pos` score as the probability of a review comment to be positive. To plot the ROC curve, these probabilities should range from `0` to `1`, so the values of the `y_vader_prob` list will be normalized using [min-max normalization](https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization)).\n",
    "\n",
    "* Normalize the data stored in the `y_vader_prob` list and save the resulting normalized values in a variable called `y_vader_prob_norm`.\n",
    "\n",
    "_Hint:_ To normalize the data, you can use the `MinMaxScaler` method from `sklearn`, or you can code the min-max normalization formula using a comprehension list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11990408],\n",
       "       [0.37170264],\n",
       "       [0.31414868],\n",
       "       [0.06954436],\n",
       "       [0.10551559]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1: Normalizing data using MinMaxScaler from sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np.array(y_vader_prob).reshape(-1,1))\n",
    "y_vader_prob_norm = scaler.transform(np.array(y_vader_prob).reshape(-1,1))\n",
    "y_vader_prob_norm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11990407673860909,\n",
       " 0.3717026378896882,\n",
       " 0.3141486810551559,\n",
       " 0.06954436450839328,\n",
       " 0.10551558752997599]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2: Using a comprehension list (OPTIONAL - RATHER USE MINMAXScaler)\n",
    "normalized = [(x - min(y_vader_prob)) / (max(y_vader_prob) - min(y_vader_prob))\n",
    "              for x in y_vader_prob]\n",
    "normalized[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Sentiment Using RNN LSTM\n",
    "\n",
    "In this section, you will build an RNN LSTM model to score the sentiment of the review comments. You will fit the model using the training and validations sets, and finally, you will get some predictions using the testing set for further performance assessment and comparison with VADER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start encoding the review comments using the `Tokenizer` method from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Tokenizer method from Keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instance of the `Tokenizer`, and fit it with all the review comments that you stored in `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Tokenizer and fit it with the X text data\n",
    "tokenizer = Tokenizer(lower=True)\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing proposes, print the first five elements of the encoded vocabulary created with the `Tokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: 'intel', token: 1\n",
      "word: 'deliver', token: 2\n",
      "word: ''ve', token: 3\n",
      "word: 'product', token: 4\n",
      "word: 'technology', token: 5\n"
     ]
    }
   ],
   "source": [
    "# Print the first five elements of the encoded vocabulary\n",
    "for token in list(tokenizer.word_index)[:5]:\n",
    "    print(f\"word: '{token}', token: {tokenizer.word_index[token]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit the RNN LSTM model for sentiment scoring, the text data in `X` should be encoded as sequences. Use the `text_to_sequence()` method of the `tokenizer` to transform the text data to numerical sequences and save the sequences in a variable called `X_seq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the text data to numerical sequences\n",
    "X_seq = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing proposes, compare the text representation of a movie review with its numerical representation, by printing the first text review in `X` and the first encoded element in `X_seq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text comment**\n",
      "{\"'ve qualify several new product fourth quarter incredibly excite lineup cpu\"}\n"
     ]
    }
   ],
   "source": [
    "# Contrast a sample numerical sequence with its text version\n",
    "print(\"**Text comment**\")\n",
    "print({X[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Numerical sequence representation**\n",
      "[3, 126, 63, 127, 4, 34, 14, 128, 35, 64, 18]\n"
     ]
    }
   ],
   "source": [
    "print(\"**Numerical sequence representation**\")\n",
    "print(X_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that RNN LSTM models need equal size inputs, so that, pad the sequences stored in `X_pad` up to `140` integers using the `pad_sequences` method from Keras. Store the pad size in a variable called `max_words`.\n",
    "\n",
    "**Note:** You may use a bigger padding size; however, using a bigger value will increase the time that takes fitting the RNN LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pad_sequences method from Keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the pad size\n",
    "max_words = 140\n",
    "\n",
    "# Pad the sequences using the pad_sequences() method\n",
    "X_pad = pad_sequences(X_seq, maxlen=max_words, padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Training, Validation, and Testing Sets\n",
    "\n",
    "You need to create suitable training, validation, and testing sets for fitting and testing the RNN LSTM model using the encoded review comments. Use the `train_test_split` method from `sklearn` to create these sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training, validation, and testing sets using the encoded data\n",
    "X_train_rnn, X_test_rnn, y_train_rnn, y_test_rnn = train_test_split(X_pad, y)\n",
    "\n",
    "X_train_rnn, X_val_rnn, y_train_rnn, y_val_rnn = train_test_split(X_train_rnn, y_train_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Train the RNN LSTM Model\n",
    "\n",
    "Remember that we use `Embedding` layers to analyze text data in RNN LSTM models, so this section starts by setting-up some initial variables needed for the RNN LSTM to score sentiment.\n",
    "\n",
    "As it's defined in the [Embedding layer documentation of the Keras API](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding?version=stable), you should set the `input_dim` parameter to the size of your vocabulary, so we set the `vocabulary_size` variable to the length of the number of words in the `tokenizer` plus `1`.\n",
    "\n",
    "Also, we define a variable called `embedding_size` to specify how many dimensions will be used to represent each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras modules for model creation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model set-up\n",
    "vocabulary_size = len(tokenizer.word_counts.keys()) + 1\n",
    "embedding_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an RNN LSTM model as follows:\n",
    "\n",
    "* _Layer 1:_ Add an `Embedding` layer using the `vocabulary_size` and `embedding_size` variables as the first two parameters, and setting `input_length=max_words` (the same size as the padding).\n",
    "\n",
    "* _Layer 2:_ Add an LSTM layer with `280` units.\n",
    "\n",
    "* _Output Layer:_ Add a `Dense` layer with `1` unit and `sigmoid` as activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=280))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model using the `binary_crossentropy` loss function, the `adam` optimizer, and fetch the following metrics: Accuracy, True positives, True negatives, False positives, False negatives, Precision, Recall, and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "        tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "        tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "        tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the summary of the model using the `summary` method of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 140, 64)           24448     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 280)               386400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 281       \n",
      "=================================================================\n",
      "Total params: 411,129\n",
      "Trainable params: 411,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the RNN LSTM model using a batch size equals to `1000` and ten epochs. Remember to set the `validation_data` parameter to use your validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 0.6444 - accuracy: 0.7083 - tp: 17.0000 - tn: 0.0000e+00 - fp: 7.0000 - fn: 0.0000e+00 - precision: 0.7083 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.8231 - val_accuracy: 0.3333 - val_tp: 3.0000 - val_tn: 0.0000e+00 - val_fp: 6.0000 - val_fn: 0.0000e+00 - val_precision: 0.3333 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 1s 549ms/step - loss: 0.6157 - accuracy: 0.7083 - tp: 17.0000 - tn: 0.0000e+00 - fp: 7.0000 - fn: 0.0000e+00 - precision: 0.7083 - recall: 1.0000 - auc: 0.5000 - val_loss: 1.2187 - val_accuracy: 0.3333 - val_tp: 3.0000 - val_tn: 0.0000e+00 - val_fp: 6.0000 - val_fn: 0.0000e+00 - val_precision: 0.3333 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 0.6429 - accuracy: 0.7083 - tp: 17.0000 - tn: 0.0000e+00 - fp: 7.0000 - fn: 0.0000e+00 - precision: 0.7083 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.9270 - val_accuracy: 0.3333 - val_tp: 3.0000 - val_tn: 0.0000e+00 - val_fp: 6.0000 - val_fn: 0.0000e+00 - val_precision: 0.3333 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 1s 567ms/step - loss: 0.6037 - accuracy: 0.7083 - tp: 17.0000 - tn: 0.0000e+00 - fp: 7.0000 - fn: 0.0000e+00 - precision: 0.7083 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.8542 - val_accuracy: 0.3333 - val_tp: 3.0000 - val_tn: 0.0000e+00 - val_fp: 6.0000 - val_fn: 0.0000e+00 - val_precision: 0.3333 - val_recall: 1.0000 - val_auc: 0.5000\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 0.6095 - accuracy: 0.7083 - tp: 17.0000 - tn: 0.0000e+00 - fp: 7.0000 - fn: 0.0000e+00 - precision: 0.7083 - recall: 1.0000 - auc: 0.5000 - val_loss: 0.8285 - val_accuracy: 0.3333 - val_tp: 3.0000 - val_tn: 0.0000e+00 - val_fp: 6.0000 - val_fn: 0.0000e+00 - val_precision: 0.3333 - val_recall: 1.0000 - val_auc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13ba7fae188>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "batch_size = 1000\n",
    "epochs = 5\n",
    "model.fit(\n",
    "    X_train_rnn,\n",
    "    y_train_rnn,\n",
    "    validation_data=(X_val_rnn, y_val_rnn),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `predict_classes` method of your model to score the sentiment setting `batch_size=1000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict classes using the testing data\n",
    "y_rnn_pred = model.predict_classes(X_test_rnn, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnimplementedError",
     "evalue": " Cast string to float is not supported\n\t [[node sequential/Cast (defined at <ipython-input-34-0ff875974e75>:1) ]] [Op:__inference_predict_function_7403]\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-0ff875974e75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredicted2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"int32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pyvizenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node sequential/Cast (defined at <ipython-input-34-0ff875974e75>:1) ]] [Op:__inference_predict_function_7403]\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "predicted2 = (model.predict(X_test[:10])>0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Comparison\n",
    "\n",
    "In this section, you will assess the performance of VADER and the RNN LSTM to score sentiment to decide which one is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "Use the `accuracy_score` method from `sklearn` to calculate the accuracy of each model. Display the results for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vader Accuracy: 0.82\n",
      "RNN LSTM Accuracy 0.73\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Vader Accuracy: %.2f\" % (accuracy_score(y_test, y_vader_pred)))\n",
    "print(\"RNN LSTM Accuracy %.2f\" % (accuracy_score(y_test_rnn, y_rnn_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Scoring the sentiment of the movie reviews as positive or negative is a binary classification problem, so use the `confusion_matrix` method from `sklearn` to calculate the confusion matrix for VADER and the RNN LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the confusion_matrix method from sklearn\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix for VADER\n",
    "\n",
    "Create the confusion matrix for vader passing the `y_test` and `y_vader_pred` variables as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix from Vader\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Positive(1)</th>\n",
       "      <th>Negative(0)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive(1)</th>\n",
       "      <td>TP=9</td>\n",
       "      <td>FN=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative(0)</th>\n",
       "      <td>FP=2</td>\n",
       "      <td>TN=0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   Positive(1) Negative(0)\n",
       "Actual                             \n",
       "Positive(1)        TP=9        FN=0\n",
       "Negative(0)        FP=2        TN=0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrtix metrics from Vader\n",
    "tn_vader, fp_vader, fn_vader, tp_vader = confusion_matrix(y_test, y_vader_pred).ravel()\n",
    "\n",
    "# Dataframe to display confusion matrix from Vader\n",
    "cm_vader_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Positive(1)\": [f\"TP={tp_vader}\", f\"FP={fp_vader}\"],\n",
    "        \"Negative(0)\": [f\"FN={fn_vader}\", f\"TN={tn_vader}\"],\n",
    "    },\n",
    "    index=[\"Positive(1)\", \"Negative(0)\"],\n",
    ")\n",
    "cm_vader_df.index.name = \"Actual\"\n",
    "cm_vader_df.columns.name = \"Predicted\"\n",
    "print(\"Confusion Matrix from Vader\")\n",
    "display(cm_vader_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix for the RNN LSTM Model\n",
    "\n",
    "Create the confusion matrix for the RNN LSTM model passing the `y_test_rnn` and `y_rnn_pred` variables as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix from the RNN LSTM Model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Positive(1)</th>\n",
       "      <th>Negative(0)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive(1)</th>\n",
       "      <td>TP=8</td>\n",
       "      <td>FN=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative(0)</th>\n",
       "      <td>FP=3</td>\n",
       "      <td>TN=0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   Positive(1) Negative(0)\n",
       "Actual                             \n",
       "Positive(1)        TP=8        FN=0\n",
       "Negative(0)        FP=3        TN=0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrtix metrics from the RNN LSTM model\n",
    "tn_rnn, fp_rnn, fn_rnn, tp_rnn = confusion_matrix(y_test_rnn, y_rnn_pred).ravel()\n",
    "\n",
    "# Dataframe to display confusion matrix from the RNN LSTM model\n",
    "cm_rnn_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Positive(1)\": [f\"TP={tp_rnn}\", f\"FP={fp_rnn}\"],\n",
    "        \"Negative(0)\": [f\"FN={fn_rnn}\", f\"TN={tn_rnn}\"],\n",
    "    },\n",
    "    index=[\"Positive(1)\", \"Negative(0)\"],\n",
    ")\n",
    "cm_rnn_df.index.name = \"Actual\"\n",
    "cm_rnn_df.columns.name = \"Predicted\"\n",
    "print(\"Confusion Matrix from the RNN LSTM Model\")\n",
    "display(cm_rnn_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "\n",
    "Use the `classification_report` from `sklearn` and generate a report for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the classification_report method from sklearn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Vader\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.82      0.90        11\n",
      "\n",
      "    accuracy                           0.82        11\n",
      "   macro avg       0.50      0.41      0.45        11\n",
      "weighted avg       1.00      0.82      0.90        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display classification report for Vader\n",
    "print(\"Classification Report for Vader\")\n",
    "print(classification_report(y_vader_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the RNN LSTM Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.73      0.84        11\n",
      "\n",
      "    accuracy                           0.73        11\n",
      "   macro avg       0.50      0.36      0.42        11\n",
      "weighted avg       1.00      0.73      0.84        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display classification report for the RNN LSTM Model\n",
    "print(\"Classification Report for the RNN LSTM Model\")\n",
    "print(classification_report(y_rnn_pred, y_test_rnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the ROC Curve\n",
    "\n",
    "In this section, you will visually analyze the performance of both models by plotting the ROC Curve. You will use the `roc_curve` and `auc` methods from `sklearn` to gather the data needed to plot this curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the roc_curve and auc metrics from sklearn\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve - VADER\n",
    "\n",
    "Use the `roc_curve` method from `sklearn` to calculate the false positives (`fpr`) and true positives (`tpr`) rates passing as parameters the testing target sentiments (`y_test`) and the normalized values of `y_vader_prob` (e.g. `y_vader_prob_norm`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for ROC Curve - VADER\n",
    "fpr_test_vader, tpr_test_vader, thresholds_test_vader = roc_curve(y_test, y_vader_prob_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating the `fpr` and `tpr` for VADER, use the `auc` method of `sklearn` to calculate the AUC for VADER. Round the final result up to `4` decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC for VADER\n",
    "auc_test_vader = auc(fpr_test_vader, tpr_test_vader)\n",
    "auc_test_vader = round(auc_test_vader, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you gather all the data needed to plot the ROC curve, create a DataFrame with the `fpr` and `tpr` data from VADER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to plot ROC Curve for VADER\n",
    "roc_df_test_vader = pd.DataFrame({\"FPR Test\": fpr_test_vader, \"TPR Test\": tpr_test_vader,})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `plot()` method of the DataFrame, plot the ROC Curve in red color and show the AUC value in the plot title.\n",
    "\n",
    "_Hint:_ You can pass `xlim=([-0.05, 1.05])` as a parameter to the `plot()` method to better adjust the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Test ROC Curve - Vader (AUC=0.8889)'}, xlabel='FPR Test'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_df_test_vader.plot(\n",
    "    x=\"FPR Test\",\n",
    "    y=\"TPR Test\",\n",
    "    color=\"red\",\n",
    "    style=\"--\",\n",
    "    xlim=([-0.05, 1.05]),\n",
    "    title=f\"Test ROC Curve - Vader (AUC={auc_test_vader})\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve RNN LSTM\n",
    "\n",
    "Use the `predict()` method from the RNN LSTM model to predict the sentiment of the testing data `X_test_rnn`. Set `batch_size=1000` to speed up the predictions and store the results in a variable called `test_predictions_rnn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions to feed the roc_curve module\n",
    "test_predictions_rnn = model.predict(X_test_rnn, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `roc_curve` method from `sklearn` to calculate the false positives (`fpr`) and true positives (`tpr`) rates passing as parameters the testing target sentiments (`y_test_rnn`) and the predictions you compute using the testing data (`test_predictions_rnn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for ROC Curve - RNN LSTM Model\n",
    "fpr_test_rnn, tpr_test_rnn, thresholds_test_rnn = roc_curve(y_test_rnn, test_predictions_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating the `fpr` and `tpr` for the RNN LSTM Model, use the `auc` method of `sklearn` to calculate the AUC for this model. Round the final result up to `4` decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC for the RNN LSTM Model\n",
    "auc_test_rnn = auc(fpr_test_rnn, tpr_test_rnn)\n",
    "auc_test_rnn = round(auc_test_rnn, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you gather all the data needed to plot the ROC curve, create a DataFrame with the `fpr` and `tpr` data from the RNN LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to plot ROC Curve for the RNN LSTM model\n",
    "roc_df_test_rnn = pd.DataFrame({\"FPR Test\": fpr_test_rnn, \"TPR Test\": tpr_test_rnn,})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `plot()` method of the DataFrame, plot the ROC Curve in blue color and show the AUC value in the plot title.\n",
    "\n",
    "_Hint:_ You can pass `xlim=([-0.05, 1.05])` as a parameter to the `plot()` method to better adjust the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Test ROC Curve (AUC=0.5)'}, xlabel='FPR Test'>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_df_test_rnn.plot(\n",
    "    x=\"FPR Test\",\n",
    "    y=\"TPR Test\",\n",
    "    color=\"blue\",\n",
    "    style=\"--\",\n",
    "    xlim=([-0.05, 1.05]),\n",
    "    title=f\"Test ROC Curve (AUC={auc_test_rnn})\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis and Conclusions\n",
    "\n",
    "Review all the metrics you computed, evaluate the ROC curve plots, and the AUC values to answer the following question:\n",
    "\n",
    "* Which model performed best scoring sentiments?\n",
    "\n",
    "    **Sample Answer:** After reviewing the results, we can conclude that the RNN LSTM model has a better performance to score sentiment. The RNN model has a higher accuracy and `F1` score values. Also, its ROC Curve plot has a better shape whose area under the curve (AUC) is very close to `1`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
